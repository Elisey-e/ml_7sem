{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e65fd3db",
   "metadata": {},
   "source": [
    "# # Спам-фильтр на выборке UCI Spambase\n",
    "# Нотебук: анализ данных, препроцессинг, эксперименты с Перцептроном и Логистической регрессией, подбор гиперпараметров, сравнение итоговых моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5e894b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Библиотеки и настройки\n",
    "import os, io, zipfile, warnings, textwrap, itertools, json, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, StratifiedKFold, RepeatedStratifiedKFold,\n",
    "    cross_validate, GridSearchCV, validation_curve, learning_curve\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, ConfusionMatrixDisplay,\n",
    "    roc_auc_score, roc_curve, auc, precision_recall_curve, average_precision_score\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.utils import Bunch\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5050820",
   "metadata": {},
   "source": [
    "# ## Загрузка датасета\n",
    "# * Предпочтительно читаем локальные файлы (`spambase.data`, `spambase.names`/`DOCUMENTATION`).\n",
    "# * Если их нет — пробуем скачать с UCI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c3a7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Имена признаков из документации UCI (57 признаков + целевая переменная 'spam')\n",
    "word_freq = [\n",
    "    \"make\",\"address\",\"all\",\"3d\",\"our\",\"over\",\"remove\",\"internet\",\"order\",\"mail\",\"receive\",\n",
    "    \"will\",\"people\",\"report\",\"addresses\",\"free\",\"business\",\"email\",\"you\",\"credit\",\"your\",\n",
    "    \"font\",\"000\",\"money\",\"hp\",\"hpl\",\"george\",\"650\",\"lab\",\"labs\",\"telnet\",\"857\",\"data\",\"415\",\n",
    "    \"85\",\"technology\",\"1999\",\"parts\",\"pm\",\"direct\",\"cs\",\"meeting\",\"original\",\"project\",\"re\",\n",
    "    \"edu\",\"table\",\"conference\"\n",
    "]\n",
    "char_freq = [\";\",\"(\", \"[\",\"!\",\"$\",\"#\"]\n",
    "char_freq = [f\"char_freq_{c}\" for c in [\"semicolon\",\"lbracket\",\"lparen\",\"exclam\",\"dollar\",\"hash\"]]\n",
    "capital_feats = [\"capital_run_length_average\",\"capital_run_length_longest\",\"capital_run_length_total\"]\n",
    "SPAMBASE_COLUMNS = [f\"word_freq_{w}\" for w in word_freq] + char_freq + capital_feats + [\"spam\"]\n",
    "\n",
    "def load_spambase(path: str = \".\") -> pd.DataFrame:\n",
    "    # 1) прямой файл\n",
    "    for fname in [\"spambase.data\", \"spambase.csv\"]:\n",
    "        f = os.path.join(path, fname)\n",
    "        if os.path.exists(f):\n",
    "            df = pd.read_csv(f, header=None, names=SPAMBASE_COLUMNS)\n",
    "            return df\n",
    "    # 2) zip-архив\n",
    "    zf = os.path.join(path, \"spambase.zip\")\n",
    "    if os.path.exists(zf):\n",
    "        with zipfile.ZipFile(zf, \"r\") as z:\n",
    "            inner = [n for n in z.namelist() if n.endswith(\"spambase.data\")]\n",
    "            if inner:\n",
    "                with z.open(inner[0]) as f:\n",
    "                    df = pd.read_csv(f, header=None, names=SPAMBASE_COLUMNS)\n",
    "                    return df\n",
    "    # 3) загрузка с UCI\n",
    "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\"\n",
    "    try:\n",
    "        df = pd.read_csv(url, header=None, names=SPAMBASE_COLUMNS)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(\"Не удалось найти ни локальные файлы, ни загрузить с UCI.\") from e\n",
    "\n",
    "df = load_spambase()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780cde81",
   "metadata": {},
   "source": [
    "# ## Базовый анализ\n",
    "# Размер датасета, типы, пропуски, баланс классов, описательная статистика."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175ba53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Размер:\", df.shape)\n",
    "print(df.dtypes.value_counts())\n",
    "print(\"Число пропусков всего:\", int(df.isna().sum().sum()))\n",
    "print(\"Баланс классов (0=ham, 1=spam):\")\n",
    "print(df[\"spam\"].value_counts().rename(\"count\").to_frame().assign(frac=lambda s: s[\"count\"]/len(df)))\n",
    "\n",
    "print(df.describe().T.round(3).iloc[:10])  # первые 10 признаков для компактности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac15d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Корреляции и наиболее коррелирующие признаки с целевой\n",
    "corr = df.corr(numeric_only=True)\n",
    "top_to_spam = corr[\"spam\"].sort_values(key=np.abs, ascending=False).head(15)\n",
    "print(top_to_spam.to_frame(\"corr_with_spam\").round(3))\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=top_to_spam.index, y=top_to_spam.values)\n",
    "plt.xticks(rotation=60, ha=\"right\")\n",
    "plt.title(\"Наиболее коррелирующие признаки с целевой\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260d83f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Топ распределений для нескольких признаков + сравнение классов\n",
    "cols_demo = [\"word_freq_free\",\"word_freq_your\",\"word_freq_money\",\"char_freq_exclam\",\n",
    "             \"capital_run_length_average\",\"capital_run_length_longest\"]\n",
    "melted = df[cols_demo+[\"spam\"]].melt(\"spam\", var_name=\"feature\", value_name=\"value\")\n",
    "g = sns.FacetGrid(melted, col=\"feature\", col_wrap=3, height=3, sharex=False, sharey=False, hue=\"spam\")\n",
    "g.map(sns.kdeplot, \"value\", common_norm=False, fill=True, alpha=0.4)\n",
    "g.add_legend(title=\"spam\")\n",
    "plt.suptitle(\"Плотности распределений по классам\", y=1.03)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2743f2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Быстрый 2D-обзор: PCA\n",
    "from sklearn.decomposition import PCA\n",
    "X_num = df.drop(columns=[\"spam\"]).values\n",
    "y = df[\"spam\"].values\n",
    "X_pca = PCA(n_components=2, random_state=RANDOM_STATE).fit_transform(X_num)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.scatter(X_pca[:,0], X_pca[:,1], c=y, s=12, alpha=0.6, cmap=\"coolwarm\")\n",
    "plt.title(\"PCA (2 компоненты)\")\n",
    "plt.xlabel(\"PC1\"); plt.ylabel(\"PC2\"); plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47cd9d9",
   "metadata": {},
   "source": [
    "# ## Препроцессинг\n",
    "# * Категориальные → OneHot (на всякий случай, хотя в Spambase их нет).\n",
    "# * Числовые → StandardScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ce05b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выделение типов признаков\n",
    "feature_cols = [c for c in df.columns if c!=\"spam\"]\n",
    "cat_cols = [c for c in feature_cols if df[c].dtype==\"object\"]\n",
    "num_cols = [c for c in feature_cols if c not in cat_cols]\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), num_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), cat_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    verbose_feature_names_out=False\n",
    ")\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df[\"spam\"].astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Train: {X_train.shape}, Test: {X_test.shape}, Spam rate train: {y_train.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154b3de3",
   "metadata": {},
   "source": [
    "# ## Базовые модели (без подбора)\n",
    "# Стартовые оценки по 5-крж кросс-валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ab44a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "scoring = {\"roc_auc\":\"roc_auc\", \"f1\":\"f1\", \"bal_acc\":\"balanced_accuracy\", \"ap\":\"average_precision\"}\n",
    "\n",
    "def evaluate_cv(pipe, X, y, name):\n",
    "    res = cross_validate(pipe, X, y, cv=cv, scoring=scoring, n_jobs=-1, return_train_score=False)\n",
    "    row = {f\"cv_{k}\":res[f\"test_{k}\"].mean() for k in scoring}\n",
    "    row.update({f\"std_{k}\":res[f\"test_{k}\"].std() for k in scoring})\n",
    "    row[\"model\"] = name\n",
    "    return row\n",
    "\n",
    "pipe_lr_base = Pipeline([(\"prep\", preprocess),\n",
    "                         (\"clf\", LogisticRegression(max_iter=500, solver=\"saga\", random_state=RANDOM_STATE))])\n",
    "\n",
    "pipe_pc_base = Pipeline([(\"prep\", preprocess),\n",
    "                         (\"clf\", Perceptron(random_state=RANDOM_STATE))])\n",
    "\n",
    "rows = []\n",
    "rows.append(evaluate_cv(pipe_lr_base, X, y, \"LogReg base\"))\n",
    "rows.append(evaluate_cv(pipe_pc_base, X, y, \"Perceptron base\"))\n",
    "cv_table = pd.DataFrame(rows).set_index(\"model\").sort_values(\"cv_roc_auc\", ascending=False)\n",
    "print(cv_table.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ce7b72",
   "metadata": {},
   "source": [
    "# ## Подбор гиперпараметров\n",
    "# Гриды и много-метрическая оптимизация."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc37d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Логистическая регрессия: C, penalty, l1_ratio, class_weight\n",
    "pipe_lr = Pipeline([\n",
    "    (\"prep\", preprocess),\n",
    "    (\"clf\", LogisticRegression(solver=\"saga\", max_iter=5000, random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "grid_lr = [\n",
    "    {\"clf__penalty\": [\"l2\"],\n",
    "     \"clf__C\": np.logspace(-3, 3, 13),\n",
    "     \"clf__class_weight\": [None, \"balanced\"]},\n",
    "    {\"clf__penalty\": [\"l1\"],\n",
    "     \"clf__C\": np.logspace(-3, 3, 13),\n",
    "     \"clf__class_weight\": [None, \"balanced\"]},\n",
    "    {\"clf__penalty\": [\"elasticnet\"],\n",
    "     \"clf__l1_ratio\": [0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "     \"clf__C\": np.logspace(-3, 3, 13),\n",
    "     \"clf__class_weight\": [None, \"balanced\"]},\n",
    "]\n",
    "\n",
    "gs_lr = GridSearchCV(\n",
    "    pipe_lr, grid_lr, cv=cv, scoring=\"roc_auc\", n_jobs=-1, verbose=0, refit=True\n",
    ")\n",
    "gs_lr.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best LR params:\", gs_lr.best_params_)\n",
    "print(\"Best CV ROC-AUC:\", gs_lr.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a27601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Перцептрон: penalty, alpha, l1_ratio, class_weight, early_stopping и max_iter\n",
    "pipe_pc = Pipeline([\n",
    "    (\"prep\", preprocess),\n",
    "    (\"clf\", Perceptron(random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "grid_pc = {\n",
    "    \"clf__penalty\": [None, \"l2\", \"l1\", \"elasticnet\"],\n",
    "    \"clf__alpha\": np.logspace(-6, -1, 6),\n",
    "    \"clf__l1_ratio\": [0.0, 0.15, 0.5, 0.85],\n",
    "    \"clf__class_weight\": [None, \"balanced\"],\n",
    "    \"clf__early_stopping\": [True],\n",
    "    \"clf__validation_fraction\": [0.1, 0.2],\n",
    "    \"clf__max_iter\": [2000, 4000],\n",
    "    \"clf__eta0\": [0.1, 1.0],\n",
    "    \"clf__shuffle\": [True]\n",
    "}\n",
    "\n",
    "gs_pc = GridSearchCV(\n",
    "    pipe_pc, grid_pc, cv=cv, scoring=\"roc_auc\", n_jobs=-1, verbose=0, refit=True\n",
    ")\n",
    "gs_pc.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Perceptron params:\", gs_pc.best_params_)\n",
    "print(\"Best CV ROC-AUC:\", gs_pc.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbfae3c",
   "metadata": {},
   "source": [
    "# ## Итоговая оценка на отложенном тесте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebd19cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_test(estimator, X_train, y_train, X_test, y_test, name=\"model\"):\n",
    "    est = estimator\n",
    "    y_proba = est.predict_proba(X_test)[:,1] if hasattr(est, \"predict_proba\") else None\n",
    "    y_dec = est.decision_function(X_test) if hasattr(est, \"decision_function\") else None\n",
    "    y_pred = est.predict(X_test)\n",
    "\n",
    "    print(f\"=== {name} ===\")\n",
    "    print(classification_report(y_test, y_pred, digits=4))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(cm, display_labels=[\"ham\",\"spam\"])\n",
    "    disp.plot(values_format=\"d\"); plt.title(f\"Confusion Matrix: {name}\"); plt.show()\n",
    "\n",
    "    if y_proba is None and y_dec is not None:\n",
    "        # приведем к [0,1] монотонным преобразованием для графиков\n",
    "        y_proba = (y_dec - y_dec.min()) / (y_dec.max() - y_dec.min() + 1e-12)\n",
    "\n",
    "    if y_proba is not None:\n",
    "        roc = roc_auc_score(y_test, y_proba)\n",
    "        fpr,tpr,_ = roc_curve(y_test, y_proba)\n",
    "        pr, rc, _ = precision_recall_curve(y_test, y_proba)\n",
    "        ap = average_precision_score(y_test, y_proba)\n",
    "\n",
    "        plt.figure(figsize=(5,4))\n",
    "        plt.plot(fpr, tpr, label=f\"AUC={auc(fpr,tpr):.4f}\")\n",
    "        plt.plot([0,1],[0,1],\"--\", lw=1)\n",
    "        plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(f\"ROC: {name}\"); plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "        plt.figure(figsize=(5,4))\n",
    "        plt.plot(rc, pr, label=f\"AP={ap:.4f}\")\n",
    "        plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(f\"PR: {name}\"); plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "        return {\"roc_auc\": roc, \"ap\": ap}\n",
    "    else:\n",
    "        return {}\n",
    "\n",
    "best_lr = gs_lr.best_estimator_\n",
    "best_pc = gs_pc.best_estimator_\n",
    "\n",
    "metrics_lr = evaluate_on_test(best_lr, X_train, y_train, X_test, y_test, \"LogisticRegression (best)\")\n",
    "metrics_pc = evaluate_on_test(best_pc, X_train, y_train, X_test, y_test, \"Perceptron (best)\")\n",
    "\n",
    "print(\"Test metrics:\")\n",
    "print(pd.DataFrame([{\"model\":\"LogReg\",\"roc_auc\":metrics_lr.get(\"roc_auc\"),\"ap\":metrics_lr.get(\"ap\")},\n",
    "                      {\"model\":\"Perceptron\",\"roc_auc\":metrics_pc.get(\"roc_auc\"),\"ap\":metrics_pc.get(\"ap\")}]).set_index(\"model\").round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283af89b",
   "metadata": {},
   "source": [
    "# ## Валидационные кривые для регуляризации\n",
    "# Как ведет себя качество при разных C (LogReg) и alpha (Perceptron)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f3daf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_val_curve(pipe, X, y, param_name, param_range, scoring=\"roc_auc\", logx=True, title=None):\n",
    "    train_scores, test_scores = validation_curve(\n",
    "        pipe, X, y, param_name=param_name, param_range=param_range,\n",
    "        cv=cv, scoring=scoring, n_jobs=-1\n",
    "    )\n",
    "    tr_mean, te_mean = train_scores.mean(axis=1), test_scores.mean(axis=1)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    if logx: \n",
    "        plt.semilogx(param_range, tr_mean, label=\"train\")\n",
    "        plt.semilogx(param_range, te_mean, label=\"cv\")\n",
    "    else:\n",
    "        plt.plot(param_range, tr_mean, label=\"train\")\n",
    "        plt.plot(param_range, te_mean, label=\"cv\")\n",
    "    plt.xlabel(param_name); plt.ylabel(scoring); \n",
    "    plt.title(title or f\"Validation curve: {param_name}\")\n",
    "    plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "pipe_lr_l2 = Pipeline([(\"prep\", preprocess),\n",
    "                       (\"clf\", LogisticRegression(penalty=\"l2\", solver=\"saga\", max_iter=5000, random_state=RANDOM_STATE))])\n",
    "\n",
    "plot_val_curve(pipe_lr_l2, X, y, \"clf__C\", np.logspace(-3, 3, 13), \"roc_auc\", True, \"LogReg (L2) — влияние C\")\n",
    "\n",
    "pipe_pc_el = Pipeline([(\"prep\", preprocess),\n",
    "                       (\"clf\", Perceptron(penalty=\"elasticnet\", random_state=RANDOM_STATE, early_stopping=True))])\n",
    "\n",
    "plot_val_curve(pipe_pc_el, X, y, \"clf__alpha\", np.logspace(-6, -1, 10), \"roc_auc\", True, \"Perceptron (elasticnet) — влияние alpha\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba57866",
   "metadata": {},
   "source": [
    "# ## Кривые обучения\n",
    "# Смотрим переобучение/недообучение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2b6d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(pipe, X, y, title):\n",
    "    sizes, train_scores, test_scores = learning_curve(\n",
    "        pipe, X, y, cv=cv, n_jobs=-1, scoring=\"roc_auc\",\n",
    "        train_sizes=np.linspace(0.1, 1.0, 8), shuffle=True, random_state=RANDOM_STATE\n",
    "    )\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(sizes, train_scores.mean(axis=1), label=\"train\")\n",
    "    plt.plot(sizes, test_scores.mean(axis=1), label=\"cv\")\n",
    "    plt.xlabel(\"Train size\"); plt.ylabel(\"ROC-AUC\"); plt.title(title)\n",
    "    plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "plot_learning_curve(best_lr, X, y, \"Learning Curve — Logistic Regression (best)\")\n",
    "plot_learning_curve(best_pc, X, y, \"Learning Curve — Perceptron (best)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521cba5c",
   "metadata": {},
   "source": [
    "# ## Интерпретация признаков для LogReg\n",
    "# Топ-коэффициенты (по абсолютной величине)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92200db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Восстановим имена фич после препроцессинга\n",
    "prep = best_lr.named_steps[\"prep\"]\n",
    "feat_names = prep.get_feature_names_out() if hasattr(prep, \"get_feature_names_out\") else np.array(feature_cols)\n",
    "\n",
    "clf_lr = best_lr.named_steps[\"clf\"]\n",
    "coefs = clf_lr.coef_.ravel()\n",
    "coef_df = pd.DataFrame({\"feature\": feat_names, \"coef\": coefs, \"abs\": np.abs(coefs)}).sort_values(\"abs\", ascending=False)\n",
    "\n",
    "top_k = 20\n",
    "fig, ax = plt.subplots(figsize=(7,6))\n",
    "sns.barplot(data=coef_df.head(top_k), x=\"abs\", y=\"feature\", hue=(coef_df.head(top_k)[\"coef\"]>0).map({True:\"+\",False:\"-\"}), dodge=False)\n",
    "ax.set_title(\"Топ весов логистической регрессии\")\n",
    "ax.set_xlabel(\"|коэффициент|\"); ax.set_ylabel(\"feature\"); ax.legend(title=\"знак\"); plt.tight_layout(); plt.show()\n",
    "\n",
    "print(coef_df.head(30).drop(columns=\"abs\").round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1914354",
   "metadata": {},
   "source": [
    "# ## Сравнение моделей и вывод\n",
    "# Печатаем сводную таблицу и краткий текстовый вывод."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f014acf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_rows = []\n",
    "\n",
    "def holdout_metrics(est, name):\n",
    "    y_proba = est.predict_proba(X_test)[:,1] if hasattr(est, \"predict_proba\") else None\n",
    "    if y_proba is None and hasattr(est, \"decision_function\"):\n",
    "        s = est.decision_function(X_test)\n",
    "        y_proba = (s - s.min())/(s.max()-s.min()+1e-12)\n",
    "    y_pred = est.predict(X_test)\n",
    "    row = dict(\n",
    "        model=name,\n",
    "        roc_auc=roc_auc_score(y_test, y_proba),\n",
    "        ap=average_precision_score(y_test, y_proba),\n",
    "        bal_acc=(confusion_matrix(y_test, y_pred, normalize=\"true\").diagonal().mean())\n",
    "    )\n",
    "    return row\n",
    "\n",
    "summary_rows.append(holdout_metrics(best_lr, \"LogReg (best)\"))\n",
    "summary_rows.append(holdout_metrics(best_pc, \"Perceptron (best)\"))\n",
    "\n",
    "summary = pd.DataFrame(summary_rows).set_index(\"model\").round(4)\n",
    "print(summary)\n",
    "\n",
    "# Краткий автоматический вывод о победителе\n",
    "best_name = summary[\"roc_auc\"].idxmax()\n",
    "print(f\"Лучшая модель по ROC-AUC на тесте: {best_name}\")\n",
    "print(\"Комментарий:\")\n",
    "print(\"* Логистическая регрессия обычно выигрывает на линейно разделимых задачах с шумом и хорошо работает с L1/L2/elasticnet регуляризацией.\\n\"\n",
    "      \"* Перцептрон чувствителен к масштабу и шуму, при этом не выдает вероятности из коробки. В этой задаче он уступает по PR/ROC.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63c585d",
   "metadata": {},
   "source": [
    "# ## Доп. эксперименты: сравнение разных регуляризаторов для LogReg\n",
    "# Трассируем средний CV ROC-AUC по `C` для L1/L2/ElasticNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30c182c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trace_lr_cv(penalty, l1_ratio=None, C_grid=np.logspace(-3,3,13)):\n",
    "    scores = []\n",
    "    for C in C_grid:\n",
    "        lr = Pipeline([(\"prep\", preprocess),\n",
    "                       (\"clf\", LogisticRegression(\n",
    "                           solver=\"saga\", penalty=penalty, l1_ratio=l1_ratio,\n",
    "                           C=C, max_iter=5000, random_state=RANDOM_STATE\n",
    "                       ))])\n",
    "        cv_res = cross_validate(lr, X, y, cv=cv, scoring=\"roc_auc\", n_jobs=-1)\n",
    "        scores.append(cv_res[\"test_score\"].mean())\n",
    "    return C_grid, np.array(scores)\n",
    "\n",
    "C_grid = np.logspace(-3,3,13)\n",
    "curves = []\n",
    "for pen in [\"l1\",\"l2\"]:\n",
    "    c, s = trace_lr_cv(penalty=pen, C_grid=C_grid)\n",
    "    curves.append((f\"LR-{pen.upper()}\", c, s))\n",
    "for l1r in [0.1,0.5,0.9]:\n",
    "    c, s = trace_lr_cv(penalty=\"elasticnet\", l1_ratio=l1r, C_grid=C_grid)\n",
    "    curves.append((f\"LR-EN(l1_ratio={l1r})\", c, s))\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "for name, c, s in curves:\n",
    "    plt.semilogx(c, s, label=name)\n",
    "plt.xlabel(\"C\"); plt.ylabel(\"CV ROC-AUC\"); plt.title(\"Регуляризация в Logistic Regression\")\n",
    "plt.legend(); plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22ce443",
   "metadata": {},
   "source": [
    "# ## Сохранение лучших моделей (при желании)\n",
    "# Модели сохраняются как pickle-файлы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e361cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib, datetime, pathlib\n",
    "outdir = pathlib.Path(\"models\")\n",
    "outdir.mkdir(exist_ok=True)\n",
    "joblib.dump(best_lr, outdir / \"logreg_best.pkl\")\n",
    "joblib.dump(best_pc, outdir / \"perceptron_best.pkl\")\n",
    "print(\"Сохранено в:\", outdir.resolve())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
